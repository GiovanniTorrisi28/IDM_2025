{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241a4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ricarica dei moduli src \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "SRC = ROOT / \"src\"\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.append(str(SRC))\n",
    "\n",
    "from task1 import *\n",
    "from task2 import *\n",
    "from task3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640455c1",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f994b",
   "metadata": {},
   "source": [
    "The dataset is structured across four merchandising levels, all organized under\n",
    "a single umbrella hierarchy. The first level represents the macro-categories,\n",
    "while the subsequent levels correspond to increasingly specific sub-categories.\n",
    "The leaves of this hierarchy represent individual products. The goal of the first\n",
    "task is to compute, for each merchandising level, the frequency of every\n",
    "element. Then, for each level, you must create two bar plots: 1) one showing\n",
    "the five most frequent elements, and 2)another showing the five least frequent\n",
    "elements. Remember to exclude shoppers from the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4624fc",
   "metadata": {},
   "source": [
    "Carichiamo il dataset tramite la funzione *load_dataset()* e applichiamo la funzione *exclude_shoppers()* per rimuovere le righe associate agli articoli di tipo SHOPPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947938ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()\n",
    "df_clean = exclude_shoppers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ee42e",
   "metadata": {},
   "source": [
    "Definiamo un dizionario che mappa ciascun livello di merchandising alla relativa colonna descrittiva. Questo ci permette di iterare facilmente sui livelli della gerarchia dell'albero merceologico e generare in sequenza le successive analisi per ognuno di essi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d251208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = {\n",
    "    \"liv1\": \"descr_liv1\",\n",
    "    \"liv2\": \"descr_liv2\",\n",
    "    \"liv3\": \"descr_liv3\",\n",
    "    \"liv4\": \"descr_liv4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9765f4d",
   "metadata": {},
   "source": [
    "Per ciascun livello di merchandising, richiamiamo la funzione *plot_frequency()* per generare i grafici delle frequenze per le categorie più e meno ricorrenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ca42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Plotting ----\n",
    "for level, desc_col in levels.items():\n",
    "    plot_frequency(df_clean, desc_col, f\"Level {level.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4840fb5",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f624150",
   "metadata": {},
   "source": [
    "The second task is similar to the first one, but requires stratifying the dataset.\n",
    "The first stratification divides the dataset into three time periods based on\n",
    "months:\n",
    "◦ Range 1: January to Mid-May\n",
    "◦ Range 2: Mid-May to September\n",
    "◦ Range 3: October to December\n",
    "For each of these ranges, you must create the same plots described in Task 1\n",
    "for every merchandising level. The second stratification is based on time slots:\n",
    "◦ Slot 1: 08:30–12:30\n",
    "◦ Slot 2: 12:30–16:30\n",
    "◦ Slot 3: 16:30–20:30\n",
    "For each time slot and each merchandising level, you again need to generate\n",
    "the same plots as in Task 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8205f7",
   "metadata": {},
   "source": [
    "Definiamo una lista di intervalli temporali per poter suddividere il dataset.  \n",
    "Ciascuno di essi è costituito da : \n",
    "- Nome dell'intervallo\n",
    "- Data di inizio\n",
    "- Data di fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a92b8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ranges = [\n",
    "    (\"Range 1: Gen - Metà Maggio\", \"2023-01-01\", \"2023-05-15\"),\n",
    "    (\"Range 2: Metà Maggio - Settembre\", \"2023-05-16\", \"2023-09-30\"),\n",
    "    (\"Range 3: Ott - Dic\", \"2023-10-01\", \"2023-12-31\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119bcc6",
   "metadata": {},
   "source": [
    "Per ciascun intervallo applichiamo un filtro sul dataframe con la funzione *filter_by_date_range(dataframe, start_date, end_date)* e poi esattamente come fatto in precedenza generiamo i grafici di frequenza per tutti i livelli di merchandising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for range_name, start_date, end_date in time_ranges:\n",
    "    df_range = filter_by_date_range(df_clean, start_date, end_date) \n",
    "    for level, desc_col in levels.items():\n",
    "        plot_frequency(df_range, desc_col, f\"{range_name} - Level {level.upper()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00b06e",
   "metadata": {},
   "source": [
    "Definiamo un'altra lista per poter suddividere il dataset in intervalli temporali orari.  \n",
    "Ciascuno di essi è costituito da : \n",
    "- Nome dell'intervallo\n",
    "- Ora di inizio\n",
    "- Ora di fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f316b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_ranges = [\n",
    "    (\"Range 1: 08:30–12:30\", \"08:30\", \"12:30\"),\n",
    "    (\"Range 2: 12:30–16:30\", \"12:30\", \"16:30\"),\n",
    "    (\"Range 3: 16:30–20:30\", \"16:30\", \"20:30\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78b598",
   "metadata": {},
   "source": [
    "Per ciascun intervallo applichiamo un filtro sul dataframe con la funzione *filter_by_hour_range(dataframe, start_hour, end_hour)* e poi esattamente come fatto in precedenza generiamo i grafici di frequenza per tutti i livelli di merchandising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ada04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for range_name, start_time, end_time in slot_ranges:\n",
    "    df_slot = filter_by_hour_range(df_clean, start_time, end_time)\n",
    "    for level, desc_col in levels.items():\n",
    "        plot_frequency(df_slot, desc_col, f\"{range_name} - {level.upper()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9de8d9",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b5615",
   "metadata": {},
   "source": [
    "Prepariamo il formato richiesto dalla funzione **apriori()**  \n",
    "Creiamo una matrice one-hot encoded con shape (n_transazioni, n_prodotti) dove ogni cella è 1 se quel prodotto è presente nella transazione, 0 altrimenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f87c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giova\\Universita\\data_mining\\IDM_2025\\first_classwork\\src\\task3.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  basket_sets = basket.drop(transaction_col, axis=1).applymap(lambda x: 1 if x > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "basket_sets = create_basket_sets(df_clean, \"scontrino_id\", \"descr_liv4\",\"r_qta_pezzi\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313f34e",
   "metadata": {},
   "source": [
    "Calcoliamo gli itemset frequenti con l'algoritmo Apriori tramite l'apposita funzione della libreria mlxtend.  \n",
    "Per motivi relativi alla capacità della RAM configuriamo una soglia di supporto pari al 3% del numero di transazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb65079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giova\\PythonEnvs\\ml_env\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.03, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e9d11",
   "metadata": {},
   "source": [
    "Calcoliamo le regole di associazione possibili e manteniamo solo quelle con una confidenza >= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4c770",
   "metadata": {},
   "source": [
    "### Analisi dei risultati ottenuti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaad02",
   "metadata": {},
   "source": [
    "Quanti itemset abbiamo ottenuto ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4c545",
   "metadata": {},
   "source": [
    "Visualizziamo i primi 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets.sort_values('support', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f770f",
   "metadata": {},
   "source": [
    "Quante regole sono state estratte ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30745b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069512e",
   "metadata": {},
   "source": [
    "Ordiniamo le regole per lift discendente e visualizziamo le 5 più interessanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(NORM.ASC.LUNGA)</td>\n",
       "      <td>(NORM.ASC.CORTA)</td>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>4.128536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(NORM.ASC.CORTA)</td>\n",
       "      <td>(NORM.ASC.LUNGA)</td>\n",
       "      <td>0.042447</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>4.128536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(SUINO)</td>\n",
       "      <td>(BOVINO)</td>\n",
       "      <td>0.049003</td>\n",
       "      <td>0.496936</td>\n",
       "      <td>2.927894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(SALAME)</td>\n",
       "      <td>(PASTE FILATE STAGIONATE)</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>2.598991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(PREPARATI GASTRON.(PANETTERIA))</td>\n",
       "      <td>(PANETTERIA PANE)</td>\n",
       "      <td>0.039576</td>\n",
       "      <td>0.672296</td>\n",
       "      <td>2.477000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         antecedents                consequents   support  \\\n",
       "30                  (NORM.ASC.LUNGA)           (NORM.ASC.CORTA)  0.042447   \n",
       "31                  (NORM.ASC.CORTA)           (NORM.ASC.LUNGA)  0.042447   \n",
       "15                           (SUINO)                   (BOVINO)  0.049003   \n",
       "49                          (SALAME)  (PASTE FILATE STAGIONATE)  0.034670   \n",
       "43  (PREPARATI GASTRON.(PANETTERIA))          (PANETTERIA PANE)  0.039576   \n",
       "\n",
       "    confidence      lift  \n",
       "30    0.552240  4.128536  \n",
       "31    0.317336  4.128536  \n",
       "15    0.496936  2.927894  \n",
       "49    0.352188  2.598991  \n",
       "43    0.672296  2.477000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_sorted = rules.sort_values('lift', ascending=False)\n",
    "rules_sorted[['antecedents','consequents','support','confidence','lift']].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
